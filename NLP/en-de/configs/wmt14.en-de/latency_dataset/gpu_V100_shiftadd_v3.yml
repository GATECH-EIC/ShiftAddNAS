lat-dataset-path: ./latency_dataset/wmt14ende_gpu_V100_shiftadd_v3.csv
lat-dataset-size: 2000 # 2000
latgpu: True
latiter: 20
latsilent: True


# below is the configs for the data point sampling space for the latency predictor

# model
arch: transformersuper_shiftadd_v2_wmt_en_de_big
share-all-embeddings: True
max-tokens: 4096
data: data/binary/wmt16_en_de

# SuperTransformer configs
encoder-embed-dim: 1024
decoder-embed-dim: 1024

encoder-ffn-embed-dim: 4096
decoder-ffn-embed-dim: 4096

encoder-layers: 6
decoder-layers: 6

encoder-attention-heads: 16
decoder-attention-heads: 16

qkv-dim: 512

act_path: 1

# SubTransformers search space
encoder-embed-choice: [1024, 768, 512]
decoder-embed-choice: [1024, 768, 512]

encoder-ffn-embed-dim-choice: [4096, 3072, 2048, 1024]
decoder-ffn-embed-dim-choice: [4096, 3072, 2048, 1024]

encoder-layer-num-choice: [6]
decoder-layer-num-choice: [6, 5, 4, 3, 2, 1]

encoder-self-attention-heads-choice: [16, 8, 4]
decoder-self-attention-heads-choice: [16, 8, 4]
decoder-ende-attention-heads-choice: [16, 8, 4]

encoder-block-types: [lightweight_conv, lightweight_add, lightweight_shiftadd, self_attention, self_attention+lightweight_conv, self_attention+lightweight_add, self_attention+lightweight_shiftadd]
decoder-block-types: [self_attention, self_attention+lightweight_conv, self_attention+lightweight_add, self_attention+lightweight_shiftadd]

# for arbitrary encoder decoder attention. -1 means attending to last one encoder layer
# 1 means last two encoder layers, 2 means last three encoder layers
decoder-arbitrary-ende-attn-choice: [-1, 1, 2]

# new added
encoder-glu: 1
decoder-glu: 1
weight-dropout: 0.03
encoder-branch-type: [attn:1:1024:4, lightweight:default:1024:4]
decoder-branch-type: [attn:1:1024:4, lightweight:default:1024:4]
conv-linear: true
my_mode: test