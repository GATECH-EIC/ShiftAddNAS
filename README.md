# ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural Networks

[![License: MIT](https://img.shields.io/badge/License-MIT-success.svg)](https://opensource.org/licenses/MIT)

**Haoran You**, Baopu Li, Huihong Shi, Yonggan Fu, Yingyan Lin

Accepted by [ICML 2022](https://icml.cc/). More Info:
\[ [**Paper**]() | [**Slide**]() | [**Youtube**]() | [**Github**](https://github.com/RICE-EIC/ShiftAddNAS) \]

---
## Usages

See CV and NLP folders for the detailed implementation.

* NLP models are inspired and developed based on [fairseq](https://github.com/facebookresearch/fairseq) and [HAT](https://github.com/mit-han-lab/hardware-aware-transformers).
* CV models are inspired and developed based on [BossNAS](https://github.com/changlin31/BossNAS) and [Autoformer](https://github.com/microsoft/Cream/tree/main/AutoFormer).

---
## Citation

If you find this codebase is useful for your research, please cite:

````
@inproceedings{ShiftAddNet,
title={ShiftAddNet: A Hardware-Inspired Deep Network},
author={Haoran You, Xiaohan Chen, Yongan Zhang, Chaojian Li, Sicheng Li, Zihao Liu, Zhangyang Wang, Yingyan Lin},
booktitle={Thirty-fourth Conference on Neural Information Processing Systems (NeurIPS)},
year={2020},
}

@inproceedings{ShiftAddNAS,
title={ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural Networks},
author={Haoran You, Baopu Li, Huihong Shi, Yonggan Fu, Yingyan Lin},
booktitle={Thirty-ninth International Conference on Machine Learning (ICML)},
year={2022},
}
````